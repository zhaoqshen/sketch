## Sql查询执行流程
![image-20210413103109010](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413103109010%20.png)
​		MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核 心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎 的功能都在这一层实现，比如存储过程、触发器、视图等。 InnoDB，它从 MySQL 5.5.5 版本开 始成为了默认存储引擎。
​		create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。

+ 连接器
  + 使用`show processlist `来查看数据库连接信息。`Command` 列显示为“`Sleep`”的这一行，就表示现在系统里面有一个空闲连接.
    客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 `wait_timeout` 控制的，默认值是 8 小时。
  + 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。建议使用长连接但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因 为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断 开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉 (OOM)，从现象看就是 MySQL 异常重启了。
  + 内存占用太大解决方案
    + 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后， 断开连接，之后要查询再重连。
    + MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 `mysql_reset_connection `来重新初始化连接资源。这个过程不需要重连和重新做权限验 证，但是会将连接恢复到刚刚创建完时的状态。
+ 查询缓存建议禁用
+ 分析器 解析SQL
+ 优化器
  + 优化器是在表里面有多个索引的时候，决定使用哪个索引;或者在一个语句有多表关联 (join)的时候，决定各个表的连接顺序。
+ 执行器
  + 先判断有没有表的查询权限如果没有，就会返 回没有权限的错误
  + 调用 InnoDB 引擎接口取这个表的第一行，判断是不是符合条件，如果不符合则跳过，如符合是则将这行存在结果集
  + 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行
  + 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
## 更新SQL执行过程

> 更新流程还涉及两个重要的日志模块 redo log(重做日志)和 binlog(归档日志)。

+ MySQL 里经常说到的 WAL 技术，WAL 的全称 是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。

+ InnoDB 引擎就会先把记录写到 redo log(粉 板)里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候， 将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

+ InnoDB 的 redo log 是固定大小的。从头开始写，写到末尾就 又回到开头循环写，如下面这个图所示。

  ![image-20210413105623239](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413105623239%20.png)

`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件 开头。
`checkpoint `是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录 更新到数据文件。
`write pos` 和 `checkpoint `之间的是“粉板”上还空着的部分，可以用来记录新的操作。如 果 `write pos `追上` checkpoint`，表示“粉板”满了，这时候不能再执行新的更新，得停下 来先擦掉一些记录，把 `checkpoint `推进一下。
有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢 失，这个能力称为**crash-safe**
redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog(归档日志)。

+ redo log 和binlog的差异

  + redo log 是 InnoDB 引擎特有的;binlog 是 MySQL 的 Server 层实现的，所有引擎都 可以使用。
  + redo log 是物理日志，记录的是“在某个数据页上做了什么修改”;binlog 是逻辑日 志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 
  + redo log 是循环写的，空间固定会用完;binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志

+ 更新语句大流程

  + 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器;否则，需要先从磁盘 读入内存，然后再返回。

  + 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新 的一行数据，再调用引擎接口写入这行新数据。

  + 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。

  + 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。

  + 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交(commit)状态，更新完成。

    ![image-20210413110315157](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413110315157%20.png)

> 将 redo log 的写入拆成了两个步骤: prepare 和 commit，这就是"两阶段提交"。

+ **怎样让数据库恢复到半个月内任意一秒的状态?**
  + binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天 一备，也可以是一周一备。
  + 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做:
    + 首先，找到最近的一次全量备份
    + 从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那 个时刻。
+ 为什么日志需要“两阶段提交”
  + redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两 个状态保持逻辑上的一致。
+ redo log 用于保证 crash-safe 能力。`innodb_flush_log_at_trx_commit` 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这样可以保证 MySQL 异常重启之后数据不丢失。

## 隔离级别

+ ACID(Atomicity、Consistency、Isolation、Durability，即原 子性、一致性、隔离性、持久性)
+ 隔离得越严实，效率就会越低
  + 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
  + 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到
  +  可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的（同一事务里两次查询的结果不一致）。
  + 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
+ 数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复 读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
+ 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要 注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念。
+ “串行 化”隔离级别下直接用加锁的方式来避免并行访问。
+ Oracle 迁移到 MySQL 的应用，为保证数据库 隔离级别的一致,将 MySQL 的隔离级别设置为“读提交”。
+ InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用 于支持 RC(Read Committed，读提交)和 RR(Repeatable Read，可重复读)隔离 级别的实现。

## 索引

+ 哈希索引 等值查询

+ 使用B+树做索引

  + B+树叶子节点含有指针可以范围查询 

  + B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。
  + B+ 树查询效率更稳定。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字

+ 有序数组索引只适用于静态存储引擎   ---忽略

+ 索引类型分为主键索引和非主键索引

  + 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引

  + 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引

  + 普通索引如果查的是非索引字段需要回表 即根据普通索引查询到主键，然后再去主键索引树查询整行数据。查询的是索引字段不需要回表。

    ![image-20210413114515259](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413114515259%20.png)

  ​       B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如 果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如 果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

  ​       而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一 个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会 受影响。

  ​      自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。

  ​		主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

+ 最左前缀原则

+ 联合索引

+ 索引下推(在存存储引擎处理）

  +  可以在索引遍历过 程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

##  全局锁和表锁

### 全局锁

+ 全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命 令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可 以使用这个命令，之后其他线程的以下语句会被阻塞:数据更新语句(数据的增删改)、数 据定义语句(包括建表、修改表结构等)和更新类事务的提交语句。
+ 全局锁的使用场景是全库逻辑备份
+ 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持， 这个过程中数据是可以正常更新的。single-transaction 方法只适用于所有的表使用事务引擎的库。

+  set global readonly=true 与FTWRL
  + 修改 global 变量的方式影响面更大。 readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库 还是备库。
  + 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开， 那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设 置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这 样会导致整个库长时间处于不可写状态，风险较高。

### 表锁

+ 表锁的语法是 lock tables ... read/write   例如：`lock tables t1 read, t2 write;`
+ 元数据锁(meta data lock， MDL) MDL 不需要显式使用，在访问一个表的时候 会被自动加上。MDL 的作用是，保证读写的正确性
  + 读锁之间不互斥
  + 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。

![image-20210413153254239](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413153254239%20.png)

+  session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要 的也是 MDL 读锁，因此可以正常执行
+ session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞
+  session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁 的请求也会被 session C 阻塞
+ 所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了

> 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满

### 死锁和死锁检测

![image-20210413160225297](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-13/image-20210413160225297%20.png)

事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行 锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态出现死锁以 后，有两种策略:

+ 一种策略是，直接进入等待，直到超时这个超时时间可以通过参数` innodb_lock_wait_timeout `来设置。
+ 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他 事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑。

> 正常情况下我们还是要采用第二种策略，即:主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。

### 两阶阶段锁

+ 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻 释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

+ 如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

## MVCC怎么工作的

+ 隐藏的三列。row_id ,事务ID，回滚指针。
+ 在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。
  + InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时 候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
  + 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本， 并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据 版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。

>  数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

+ 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。
  + 一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认;如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。
  + 上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的
  +  InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正 在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交
  + 数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。
  + 这个视图数组和高水位，就组成了当前事务的一致性视图(read-view)。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到 的。这个视图数组把所有的 row trx_id 分成了几种不同的情况。

![image-20210415145342640](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415145342640%20.png)

对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况:

1. 版本未提交，不可见;
2. 版本已提交，但是是在视图创建后提交的，不可见。
3. 版本已提交，而且是在视图创建前提交的，可见。

+ **更新数据都是先读后写的，而这个读，只能读当前的 值，称为“当前读”(current read)。**

  > select 语句如果加 锁，也是当前读。

  + 当前读, 读取的是最新版本, 并且对读取的记录加锁, 阻塞其他事务同时改动相同记录，避免出现安全问题
  + update的时候肯定要是当前读，得到最新的信息并且锁定相应的记录
  + 当前读的实现方式：next-key锁(行记录锁+Gap间隙锁)
    + 锁定范围空间的数据，假设id有3,4,5，锁定id>3的数据，是指的4，5及**后面的数字都会被锁定，**因为此时如果不锁定没有的数据，例如当加入了新的数据id=6，就会出现幻读，间隙锁避免了幻读。
    + 对主键或唯一索引，如果当前读时，where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加行记录锁（锁住的是索引记录——索引锁）
    + 没有索引的列，当前读操作时，会加全表gap锁（间隙锁）
    + 非唯一索引列，如果where条件部分命中(>、<、like等)或者全未命中，则会加附近Gap间隙锁

## Mysql 锁



## 普通索引和唯一索引

### 查询过程

+ 对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直 到碰到第一个不满足 条件的记录。
+ 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止 继续检索。

> InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时 候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存 里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只 需要一次指针寻找和一次计算

### 更新过程

+ 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内 存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的 时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方 式就能保证这个数据逻辑的正确性。

+ change buffer 在内存中有拷贝，也会被写入到磁盘上。将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问 这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭 (shutdown)的过程中，也会执行 merge 操作。

+ 这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下:

  + 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束;
  + 对于普通索引来说，则是将更新记录在 change bu ffer，语句执行就结束了

  > 多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好
  >
  > 业务的更新模式是写入之后马上会做查询.先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。 这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这 种业务模式来说，change buffer 反而起到了副作用。

**redo log 主要节省的 是随机写磁盘的 IO 消耗(转成顺序写)，而 change buffer 主要节省的则是随机读磁盘 的 IO 消耗。**

## 数据库表的空间回收

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table `控制的:

+ OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在 一起;
+ ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件 中。 5.6.6 版本开始，它的默认值就是 ON 

>  drop table 命令回收表空间

delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但 磁盘文件的大小是不会变的。

+ 记录的复用，只限于符合范围条件的数据。
+ 页复用是整个页面的都可以复用

可以被复用但是没有使用的空间称为空洞。大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去
掉，就能达到收缩表空间的目的。可以使用 alter table A engine=InnoDB 命令来重建表

> 数据库本身就是紧凑的情况会变大 在 DDL 期间，如果刚好有外部的 DML 在执行，这期间可能会引入一些新的空洞。

## Count

+ count() 是一个聚合函数，对于返回的结果集，一 行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。

  + **count(主键 id) 来说**，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回 给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
  +  **count(1) 来说**，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行， 放一个数字“1”进去，判断是不可能为空的，按行累加。
  + **count(字段)**
    + 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不 能为 null，按行累加;
    +  如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值 取出来再判断一下，不是 null 才累加。

  + **count(\*) 是例外**，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。

> count(字段)<count(主键 id)<count(1)≈count(*)

## 排序

+ Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一 块内存用于排序，称为 sort_buffer
+ sort_buffer_size，就是 MySQL 为排序开辟的内存(sort_buffer)的大小。如果要排序的 数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不 下，则不得不利用磁盘临时文件辅助排序。
  + MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这 样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。
  + **如果内存够，就要多利用内存，尽量减少磁盘访 问。**

## 随机排序

+ order by rand() 
  + Extra 字段显示 Using temporary  Extra 的意思就是，需要临时表，并且需要在临时表上排序。

> **order by rand() 使用了内存临时表，内存临时表排序的时候 使用了 rowid 排序方法。**

+ tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临 时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。
  + 磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控 制的。

## 查询长时间不返回

+  show processlist 命令，看看当前语句处于什么状态。

  + 等MDL锁

    +  show processlist 命令查看  Waiting for table metadata lock 的
    + sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可

  + **等** **flush**

    + 同上

  + **等行锁**

    ![image-20210415165404709](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415165404709%20.png)

    ```sql
    1 mysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G
    ```

    ![image-20210415165236429](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415165236429%20.png)

> KILL QUERY 4 这个命令表示停止 4 号线程当前正在执行的语 句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执 行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。
>
> 实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被 断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。

## 幻读

+ 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的 是记录之间的“间隙”。

```sql
 insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

> 初始化插入了 6 个 记录，这就产生了 7 个间隙。

![image-20210415170942097](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415170942097%20.png)

` select * from t where d=5 for update` 的时候，就不止是给数据库中已 有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁

![image-20210415171229227](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415171229227%20.png)

+ **跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操 作。**间隙锁之间都不存在冲突关系。

![image-20210415171417461](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415171417461%20.png)

session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是 间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即:保护这 个间隙，不允许插入值。但，它们之间是不冲突的。

​		间隙锁和行锁合称 next-key lock，每个 next-key lock 是`前开后闭`区间。也就是说，我们 的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形 成了 7 个 next-key lock，分别是

 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、 (25, +supremum]。

> 间隙锁在可重复读隔离级别下才有效，

## **加锁规则**

+ 原则 1:加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭 区间。

+ 原则 2:查找过程中访问到的对象才会加锁。

+ 优化 1:索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。

+ 优化 2:索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

+ 一个 bug:唯一索引上的范围查询会访问到不满足条件的第一个值为止。

  > 1. 在普通索引列上，**不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样；**
  >
  > 2. 在普通索引跟唯一索引中，数据间隙的分析，数据行是优先根据普通索引排序，再根据唯一索引排序。
  >
  > 3. **临键锁**，是**记录锁与间隙锁的组合**，它的封锁范围，既包含索引记录，又包含索引区间。
  >
  >    **注：**临键锁的主要目的，也是为了避免**幻读**(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。
  
  ![image-20210415172358811](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415172358811%20.png)

### 等值查询的间隙锁

![image-20210415172144965](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415172144965%20.png)  

+ 由于表 t 中没有 id=7 的记录
  +  根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10];
  + 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-keylock 退化成间隙锁，因此最终加锁的范围是 (5,10)。
  + 所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。

### 非唯一索引加锁

![image-20210415174730003](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415174730003%20.png)

+ 这里 session A 要给索引 c 上 c=5 的这一行加上读锁。
+ 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 next-key lock。
+ 要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 next-key lock。
+ 但是同时这个符合优化 2:等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。
+ 根据原则 2 ，**只有访问到的对象才会加锁**，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执 行完成。
+ lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索 引上满足条件的行加上行锁。

> 锁是加在索引上的.
>
>  lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中 加入索引中不存在的字段。

### **主键索引范围锁**

![image-20210415173456053](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415173456053%20.png)

+  开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据 优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
+ 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。
+ session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]

### 非唯一索引范围锁

![image-20210415173706151](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415173706151%20.png)

+ 在第一次用 c=10 定 位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引， 没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。
+ sesson B 要插入(8,8,8) 的这个 insert 语句时就被堵住了。
+  c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要 继续往后找了。

### **唯一索引范围锁** **bug**

![image-20210415174215073](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415174215073%20.png)

+ session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next- key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了.
+ InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于 这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。
+ session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插 入 id=16 的一行，也会被锁住
+ 这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以 确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。

### 非唯一索引上存在等值的例子

```sql
 mysql> insert into t values(30,10,30);
```

![image-20210415174704321](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415174704321%20.png)

+ 虽然有两个 c=10，但是它们的主键值 id 是不同的(分别是 10 和 30)，因此 这两个 c=10 的记录之间，也是有间隙的

> delete 语句加锁的逻辑，其实跟 select ... for update 是类似的

![image-20210415174904296](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415174904296%20.png)

+ session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里 加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。
+ session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2， 这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。
+ delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。

![image-20210415175002777](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415175002777%20.png)

这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上 都没有锁

### limit 加锁

## MySQL怎么保证数据数据不丢的

### **binlog** **的写入机制**

+ 事务执行过程中，先把日志写到 binlog cache，事务 提交的时候，再把 binlog cache 写到 binlog 文件中。

  + 一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就 涉及到了 binlog cache 的保存问题。
  + 系统给 binlog cache 分配了一片内存，每个线程一个，但是共用同一份 binlog 文件。。参数 binlog_cache_size 用于控制 单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到 磁盘。
  + 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache

  ![image-20210415180049352](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415180049352%20.png)

+  write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化 到磁盘，所以速度比较快。
+  fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘 的 IOPS。
+ write 和 fsync 的时机，是由参数 sync_binlog 控制的:
  + sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync;
  + sync_binlog=1 的时候，表示每次提交事务都会执行 fsync;
  + sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。

> 将 sync_binlog 设置成一个比较大的值，可以提升性能
> sync_binlog 设置为 N，对应的风险是:如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志

### **redo log** **的写入机制**

+ 事务在执行过程中，生成 的 redo log 是要先写到 redo log buffer 的。
+ redo log buffer 里面的内容，不是每次生成后都要直接持久化到磁 盘的
+ 如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交， 所以这时日志丢了也不会有损失。
+ 事务还没提交的时候，redo log buffer 中的部分日志有可能没被持久化到磁盘。

![image-20210415180543517](https://wsx666-1302523054.cos.ap-nanjing.myqcloud.com/image/2021-04-15/image-20210415180543517%20.png)

+ 存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分;
+ 写到磁盘 (write)，但是没有持久化(fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分;
+ 持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。
+ 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参 数，它有三种可能取值:
  + 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
  + 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘;
  + 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

> InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到 文件系统的 page cache，然后调用 fsync 持久化到磁盘。
>
> 事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可 能已经持久化到磁盘的。

+ 两种场景会让一个没有提交的事务的 redo log 写入到磁盘中：

  + 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时 候，后台线程会主动写盘。由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。
  + 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁 盘。

  > 时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。

+  innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要 持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的

## 自增id用完

每种自增 id 有各自的应用场景，在达到上限后的表现也不同:

1. 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键 冲突的错误。
2. row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆 盖之前的数据。
3. Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是 概率极小，可以忽略不计。
4. InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到 的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
5. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。



### join

join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。 被驱动表的索引